{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import random \n",
    "import unidecode \n",
    "import string \n",
    "import re \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED= 234 \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE= torch.device('cpu')\n",
    "\n",
    "NUM_ITER= 5000  # epoch size \n",
    "LEARNING_RATE = 0.005 \n",
    "EMBEDDING_DIM= 100  # size of the embedding weight \n",
    "HIDDEN_DIM= 100     # size of the hidden layer \n",
    "NUM_HIDDEN_LAYER= 1     # number of hidden layer after embedding \n",
    "\n",
    "TEXT_PORTION_SIZE= 200  # size of each text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.printable    # all the ascii characters this string class can take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('covid19-faq.txt', 'r') as f:     # open the file \n",
    "    textfile= f.read()  # read the file and load into a variable called textfile \n",
    "\n",
    "textfile = unidecode.unidecode(textfile)    # convert all the special characters \n",
    "\n",
    "# get rid of all the white spaces \n",
    "textfile = re.sub(\" +\",\" \", textfile)\n",
    "\n",
    "TEXT_LENGTH= len(textfile)  # find the total length of the textfile= text_length\n",
    "\n",
    "TEXT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to be submitted. In addition, all current campus health protocols must be followed including wearing facial covering. Additional information on the campus travel policy is located here.\n",
      "\n",
      "Under current\n"
     ]
    }
   ],
   "source": [
    "random.seed(RANDOM_SEED)    # set the random seed \n",
    "# this will lead to weird texts \n",
    "def random_portion (textfile):  # sample text randomly \n",
    "    start_index= random.randint(0, TEXT_LENGTH-TEXT_PORTION_SIZE)   # randomly sample sentence with TEXT_PORTION_SIZE # of characters in it \n",
    "    end_index= start_index + TEXT_PORTION_SIZE + 1 \n",
    "    return textfile[start_index:end_index]  # return the string of that size \n",
    "\n",
    "print(random_portion(textfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# convert text into torch tensor for training purposes \n",
    "def char_to_tensor(text):\n",
    "    lst= [string.printable.index(c) for c in text]  # convert the text into ASCII characters(ASCII indices) \n",
    "    tensor= torch.tensor(lst).long()   # convert this into a tensor\n",
    "    return tensor \n",
    "print(char_to_tensor(\"abcDEF\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_sample(textfile):\n",
    "    text_long = char_to_tensor(random_portion(textfile))    # randomly get text and convert into torch tensor \n",
    "    input= text_long[:-1]   # input is every letter besides last one \n",
    "    targets= text_long[1:]   # output starts from index 1, we input one and predict the next one (that's why we cut off the last letter of )\n",
    "    return input, targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([32, 24, 94, 13, 10, 34, 28, 94, 28, 18, 23, 12, 14, 94, 29, 17, 14, 18,\n",
       "         27, 94, 21, 10, 28, 29, 94, 14, 25, 18, 28, 24, 13, 14, 94, 24, 15, 94,\n",
       "         31, 24, 22, 18, 29, 18, 23, 16, 94, 24, 27, 94, 13, 18, 10, 27, 27, 17,\n",
       "         14, 10, 78, 94, 18, 15, 94, 29, 17, 14, 34, 94, 17, 10, 31, 14, 94, 11,\n",
       "         14, 14, 23, 94, 24, 23, 94, 10, 23, 29, 18, 11, 18, 24, 29, 18, 12, 94,\n",
       "         15, 24, 27, 94, 10, 29, 94, 21, 14, 10, 28, 29, 94,  2,  4, 94, 17, 24,\n",
       "         30, 27, 28, 94, 18, 15, 94, 25, 27, 14, 28, 12, 27, 18, 11, 14, 13, 78,\n",
       "         94, 24, 27, 94, 10, 28, 94, 10, 25, 25, 27, 24, 31, 14, 13, 94, 29, 24,\n",
       "         94, 32, 24, 27, 20, 94, 11, 34, 94, 10, 94, 13, 24, 12, 29, 24, 27, 75,\n",
       "         96, 96, 48, 24, 28, 29, 94, 14, 22, 25, 21, 24, 34, 14, 14, 28, 94, 32,\n",
       "         18, 21, 21, 94, 11, 14, 94, 10, 11, 21, 14, 94, 29, 24, 94, 27, 14, 29,\n",
       "         30, 27]),\n",
       " tensor([24, 94, 13, 10, 34, 28, 94, 28, 18, 23, 12, 14, 94, 29, 17, 14, 18, 27,\n",
       "         94, 21, 10, 28, 29, 94, 14, 25, 18, 28, 24, 13, 14, 94, 24, 15, 94, 31,\n",
       "         24, 22, 18, 29, 18, 23, 16, 94, 24, 27, 94, 13, 18, 10, 27, 27, 17, 14,\n",
       "         10, 78, 94, 18, 15, 94, 29, 17, 14, 34, 94, 17, 10, 31, 14, 94, 11, 14,\n",
       "         14, 23, 94, 24, 23, 94, 10, 23, 29, 18, 11, 18, 24, 29, 18, 12, 94, 15,\n",
       "         24, 27, 94, 10, 29, 94, 21, 14, 10, 28, 29, 94,  2,  4, 94, 17, 24, 30,\n",
       "         27, 28, 94, 18, 15, 94, 25, 27, 14, 28, 12, 27, 18, 11, 14, 13, 78, 94,\n",
       "         24, 27, 94, 10, 28, 94, 10, 25, 25, 27, 24, 31, 14, 13, 94, 29, 24, 94,\n",
       "         32, 24, 27, 20, 94, 11, 34, 94, 10, 94, 13, 24, 12, 29, 24, 27, 75, 96,\n",
       "         96, 48, 24, 28, 29, 94, 14, 22, 25, 21, 24, 34, 14, 14, 28, 94, 32, 18,\n",
       "         21, 21, 94, 11, 14, 94, 10, 11, 21, 14, 94, 29, 24, 94, 27, 14, 29, 30,\n",
       "         27, 23]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_random_sample(textfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__ (self, input_size, embed_size, hidden_size, output_size, num_layers):\n",
    "        super().__init__() \n",
    "        self.hidden_size= hidden_size\n",
    "        self.num_layers= num_layers\n",
    "        self.embed= torch.nn.Embedding(num_embeddings=input_size,embedding_dim=embed_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
