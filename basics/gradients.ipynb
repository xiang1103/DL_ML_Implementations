{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients  \n",
    "PyTorch can compute the gradient of variables/weights/parameters automatically through require_grad, loss.backward, and later used in gradient descent to adjust the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.ones(6, requires_grad=True) #x is a parameter 1x6 vector, and will compute the gradient of every element the vector during gradient descent.\n",
    "\n",
    "# Otherwise, PyTorch will not auto calculate its gradients. \n",
    "\n",
    "# Require_grad will be saved into a computational graph at PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating gradients  \n",
    "Parameters of a model are variables with gradient required on them.  \n",
    "Operations done on them are all recorded in the computational graph, and when we calculate the gradient, PyTorch calculates the gradient by using chain rule.  \n",
    "\n",
    "*Note*: PyTorch uses grad_fn as the gradient function to compute gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3045, -1.3004, -1.7878], requires_grad=True)\n",
      "tensor([0.6955, 0.6996, 0.2122], grad_fn=<AddBackward0>)\n",
      "tensor(2.3394, grad_fn=<MeanBackward0>)\n",
      "tensor([0.4637, 0.4664, 0.1415])\n"
     ]
    }
   ],
   "source": [
    "x= torch.randn(3, requires_grad=True)   #make x into a 1x3 row vector parameter \n",
    "print(x)\n",
    "y= x+2  #first operation \n",
    "print(y)\n",
    "z=y*y+2     #second operation \n",
    "z=z.mean()  #another operation on the same variable \n",
    "print(z)\n",
    "\n",
    "\n",
    "z.backward()    #calculates dz/dx, calculates the gradient of all the parameters associated with z (all the variables that have gradient on, not y)\n",
    "print(x.grad)   #print out the gradient of x from dz/dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian vector product \n",
    "- When calculating the gradient, if the final output is not a scalar, we have to call tensor.backward(v) for v is a vector the same size as our parameter. This is calculating the Jacobian vector product/chain rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To not include some operations in the computation graph to calculate gradient \n",
    "# 1. with torch.no_grad() \n",
    "# 2. tensor.requires_grad_(False)\n",
    "# 3. tensor.detach() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example training:  \n",
    "let l= model_output  \n",
    "  \n",
    "gradient = dl/dx = [dl/dx1  dl/dx2  dl/dx3  dl/dx4] = [3 3 3 3], since l = 3x^2 and sums up  \n",
    "  \n",
    "With multiple operations or iterations, the gradients sum up, so if one iteration the gradient is [3 3 3 3], another iteration will also produce [3 3 3 3], and in total is [6 6 6 6]  \n",
    "  \n",
    "tensor.grad.zero_() will clear out the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights= torch.ones(4, requires_grad=True)  # our parameter \n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward() \n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
