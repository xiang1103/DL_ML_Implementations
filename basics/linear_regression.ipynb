{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77a1c3d",
   "metadata": {},
   "source": [
    "Implement linear regression with torch to fit simple lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739ab86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn \n",
    "import torch.nn.init as init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bda9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= torch.tensor([\n",
    "    (1,1), \n",
    "    (2,1),\n",
    "    (5,1), \n",
    "    (-1,1) \n",
    "], dtype=torch.float32)\n",
    "\n",
    "truth = torch.tensor([5,8,17,-1], dtype=torch.float32)\n",
    "truth = truth.view(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc8c0f",
   "metadata": {},
   "source": [
    "## Define models \n",
    "The data is made of mx+b = y, for m=3,b =1.   \n",
    "The model should figure out what m is. A very simple model \n",
    "\n",
    "(4,1) is the data size, so we can train a single layer perceptron model \n",
    "\n",
    "- For each training pair, the format is $$w_1 * x_1 + w_2 * x_2 = y$$ \n",
    "\n",
    "we want the ground truth solution of $w_1 = 3, w_2=1$\n",
    "\n",
    "With sufficient training, the model will discover the correct vector. You can see that with a very low amount of data, the model takes 17695 iterations to have a loss lower than 3e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73f1090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,1, bias=False)  # two features, 1 neuron in the next layer, which would be the output  \n",
    "    # since we included the bias in the feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a29e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb56840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17695\n",
      "Final loss: 0.002999730873852968\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (10000000): \n",
    "    prediction = model(input_data)  # matrix multiplication, [4,2] * [2,1] = [4,1]\n",
    "    loss= criterion(prediction, truth)  # element-wise that's more efficient \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    if (loss.item()< 3e-3):\n",
    "        print(epoch)\n",
    "        break \n",
    "    \n",
    "print(f\"Final loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3945a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1303, 1.4657]])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94c488",
   "metadata": {},
   "source": [
    "### What happens if we have very bad weight initialization? \n",
    "It doesn't what our weight initialization is constant or 0, since the gradient is not dependent on the weight yet \n",
    "\n",
    "Bias= False  \n",
    "- all neurons move similar weights in terms of gradient, so basically every change is diluted out, as if they are dead neurons \n",
    "- you see this with multiple neurons \n",
    "\n",
    "Bias = True \n",
    "- all neurons will move the same but bias gradient doesn't affect the weight gradient. Behavior is very similar with when bias=false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4cef862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,3, bias=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss() \n",
    "with torch.no_grad(): \n",
    "    init.zeros_(model.weight)   # initialize to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f698314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | prediction: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<MmBackward0>) | loss: 94.75\n",
      "gradient: tensor([[-17.8333,  -4.8333],\n",
      "        [-17.8333,  -4.8333],\n",
      "        [-17.8333,  -4.8333]])\n",
      "Model weights:  tensor([[0.0018, 0.0005],\n",
      "        [0.0018, 0.0005],\n",
      "        [0.0018, 0.0005]])\n",
      "Epoch: 1 | prediction: tensor([[ 0.0023,  0.0023,  0.0023],\n",
      "        [ 0.0041,  0.0041,  0.0041],\n",
      "        [ 0.0094,  0.0094,  0.0094],\n",
      "        [-0.0013, -0.0013, -0.0013]], grad_fn=<MmBackward0>) | loss: 94.64761352539062\n",
      "gradient: tensor([[-17.8236,  -4.8309],\n",
      "        [-17.8236,  -4.8309],\n",
      "        [-17.8236,  -4.8309]])\n",
      "Model weights:  tensor([[0.0036, 0.0010],\n",
      "        [0.0036, 0.0010],\n",
      "        [0.0036, 0.0010]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (2): \n",
    "    prediction = model(input_data)  \n",
    "    loss= criterion(prediction, truth)  \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "    print(f\"Epoch: {epoch} | prediction: {prediction} | loss: {loss.item()}\")\n",
    "    print(f\"gradient: {model.weight.grad}\")\n",
    "    print(\"Model weights: \", model.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "592b231f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0036, 0.0010],\n",
      "        [0.0036, 0.0010],\n",
      "        [0.0036, 0.0010]])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d989fd2b",
   "metadata": {},
   "source": [
    "### Solving Linear models \n",
    "- linear models with mse loss function can have a close form solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73cf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "X= np.array([\n",
    "    [2070, 138],\n",
    "    [138,10]\n",
    "])\n",
    "Y= np.array([3717,241])\n",
    "\n",
    "theta =np.linalg.solve(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58925cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.36231884 -8.5       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(theta)\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b278334",
   "metadata": {},
   "source": [
    "### What if the matrix is unsolvable? \n",
    "- contradictory or no solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b015fab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m X= np.array([\n\u001b[32m      2\u001b[39m     [\u001b[32m13\u001b[39m,\u001b[32m13\u001b[39m],\n\u001b[32m      3\u001b[39m     [\u001b[32m13\u001b[39m,\u001b[32m13\u001b[39m]\n\u001b[32m      4\u001b[39m ])\n\u001b[32m      5\u001b[39m Y = np.array([\u001b[32m36\u001b[39m,\u001b[32m54\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m theta = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:410\u001b[39m, in \u001b[36msolve\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m    407\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mDD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdd->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    409\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     r = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:104\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "X= np.array([\n",
    "    [13,13],\n",
    "    [13,13]\n",
    "])\n",
    "Y = np.array([36,54])\n",
    "theta = np.linalg.solve(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d670ec",
   "metadata": {},
   "source": [
    "#### What about infinite number of solutions \n",
    "- when all points in the system are linearly dependent of each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33f187e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m X=np.array([\n\u001b[32m      3\u001b[39m     [\u001b[32m5\u001b[39m,\u001b[32m5\u001b[39m], [\u001b[32m5\u001b[39m,\u001b[32m5\u001b[39m]\n\u001b[32m      4\u001b[39m ])\n\u001b[32m      5\u001b[39m Y= np.array([\u001b[32m15\u001b[39m,\u001b[32m15\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m theta=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:410\u001b[39m, in \u001b[36msolve\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m    407\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mDD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdd->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    409\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     r = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:104\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([\n",
    "    [5,5], [5,5]\n",
    "])\n",
    "Y= np.array([15,15])\n",
    "theta=np.linalg.solve(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f99ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., -3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "X= np.array([\n",
    "    [5,7], [7,10]\n",
    "])\n",
    "Y= np.array([4,5])\n",
    "theta = np.linalg.solve(X,Y)\n",
    "theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
