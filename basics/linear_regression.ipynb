{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77a1c3d",
   "metadata": {},
   "source": [
    "Implement linear regression with torch to fit simple lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739ab86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn \n",
    "import torch.nn.init as init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bda9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= torch.tensor([\n",
    "    (1,1), \n",
    "    (2,1),\n",
    "    (5,1), \n",
    "    (-1,1) \n",
    "], dtype=torch.float32)\n",
    "\n",
    "truth = torch.tensor([5,8,17,-1], dtype=torch.float32)\n",
    "truth = truth.view(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc8c0f",
   "metadata": {},
   "source": [
    "## Define models \n",
    "The data is made of mx+b = y, for m=3,b =1.   \n",
    "The model should figure out what m is. A very simple model \n",
    "\n",
    "(4,1) is the data size, so we can train a single layer perceptron model \n",
    "\n",
    "- For each training pair, the format is $$w_1 * x_1 + w_2 * x_2 = y$$ \n",
    "\n",
    "we want the ground truth solution of $w_1 = 3, w_2=1$\n",
    "\n",
    "With sufficient training, the model will discover the correct vector. You can see that with a very low amount of data, the model takes 17695 iterations to have a loss lower than 3e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73f1090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,1, bias=False)  # two features, 1 neuron in the next layer, which would be the output  \n",
    "    # since we included the bias in the feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a29e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb56840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17695\n",
      "Final loss: 0.002999730873852968\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (10000000): \n",
    "    prediction = model(input_data)  # matrix multiplication, [4,2] * [2,1] = [4,1]\n",
    "    loss= criterion(prediction, truth)  # element-wise that's more efficient \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    if (loss.item()< 3e-3):\n",
    "        print(epoch)\n",
    "        break \n",
    "    \n",
    "print(f\"Final loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3945a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1303, 1.4657]])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94c488",
   "metadata": {},
   "source": [
    "### What happens if we have very bad weight initialization? \n",
    "It doesn't what our weight initialization is constant or 0, since the gradient is not dependent on the weight yet \n",
    "\n",
    "Bias= False  \n",
    "- all neurons move similar weights in terms of gradient, so basically every change is diluted out, as if they are dead neurons \n",
    "- you see this with multiple neurons \n",
    "\n",
    "Bias = True \n",
    "- all neurons will move the same but bias gradient doesn't affect the weight gradient. Behavior is very similar with when bias=false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4cef862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,3, bias=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss() \n",
    "with torch.no_grad(): \n",
    "    init.zeros_(model.weight)   # initialize to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f698314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | prediction: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<MmBackward0>) | loss: 94.75\n",
      "gradient: tensor([[-17.8333,  -4.8333],\n",
      "        [-17.8333,  -4.8333],\n",
      "        [-17.8333,  -4.8333]])\n",
      "Model weights:  tensor([[0.0018, 0.0005],\n",
      "        [0.0018, 0.0005],\n",
      "        [0.0018, 0.0005]])\n",
      "Epoch: 1 | prediction: tensor([[ 0.0023,  0.0023,  0.0023],\n",
      "        [ 0.0041,  0.0041,  0.0041],\n",
      "        [ 0.0094,  0.0094,  0.0094],\n",
      "        [-0.0013, -0.0013, -0.0013]], grad_fn=<MmBackward0>) | loss: 94.64761352539062\n",
      "gradient: tensor([[-17.8236,  -4.8309],\n",
      "        [-17.8236,  -4.8309],\n",
      "        [-17.8236,  -4.8309]])\n",
      "Model weights:  tensor([[0.0036, 0.0010],\n",
      "        [0.0036, 0.0010],\n",
      "        [0.0036, 0.0010]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/newEnv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (2): \n",
    "    prediction = model(input_data)  \n",
    "    loss= criterion(prediction, truth)  \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "    print(f\"Epoch: {epoch} | prediction: {prediction} | loss: {loss.item()}\")\n",
    "    print(f\"gradient: {model.weight.grad}\")\n",
    "    print(\"Model weights: \", model.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "592b231f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0036, 0.0010],\n",
      "        [0.0036, 0.0010],\n",
      "        [0.0036, 0.0010]])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
