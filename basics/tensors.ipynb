{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element wise operations \n",
    "Torch supports element wise addition, substraction, multiplication, division by doing x (operation) y  \n",
    "\n",
    "#### In place operations \n",
    "All the operations with _ modifies the variable itself in place "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,2)\n",
    "y= torch.rand(2,2)\n",
    "\n",
    "z1= torch.add(x,y)\n",
    "z2= torch.sub(x,y)\n",
    "z3= torch.mul(x,y)\n",
    "z4= torch.div(x,y)\n",
    "y.mul_(x)   # in place multiplication of x into y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping tensors \n",
    "Tensor reshaping just works like that in numpy. PyTorch always makes a tensor into {1xD} row vector if truncate everything down unless otherwise specified   \n",
    "- number of elements must be the same \n",
    "- tensor.view(-1) lets pytorch determines the dimension. So PyTorch will look at the other dimensions you specified and the total number of elements and fit all the elements into the given dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.rand(4,4)\n",
    "y1 = x.view(16) #make everything into one vector (defualt will be 1x16 row vector)\n",
    "y2= x.view (-1,8)   #make this into a 2x 8 vector. 16/8=2 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "PyTorch's tensor operations are similar with numpy's array's operations. But Numpy uses CPU and tensor uses GPU(cuda).  \n",
    "\n",
    "If we copy the tensor into a numpy array (uses CPU), both the tensor and array will use the same memory location **if** tensor is also running on CPU So modifying one changes the other.  \n",
    "\n",
    "***Note***: when we make arrays in tensor, the default device is CPU. Usually if we make a tensor into numpy, it'll be in place operations. We also can't convert a GPU tensor into numpy because numpy uses CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "<class 'numpy.ndarray'>\n",
      "cpu\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a= torch.ones(5)    #make a 1x5 row vector with every element =1 \n",
    "b=a.numpy()     # make a numpy copy of a \n",
    "print (a.device)      # a is a tensor \n",
    "print(type(b))      # b is a numpy array\n",
    "\n",
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # device is currently cpu but this is also the case for GPU\n",
    "\n",
    "a.add_(1)   # in place element wise operation to add 1 \n",
    "print(a)\n",
    "print(b)    # both a and b are changed "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
